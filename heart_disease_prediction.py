# -*- coding: utf-8 -*-
"""Heart Disease Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yTr4SGEJcNCBEk9-lH6Jc4WPabrm35EW

# **HEART DISEASE PREDICTION**

**DATASET FROM :** [KAGGLE "Heart Disease Dataset"](https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset)

**1. IMPORTING LIBRARIES**
"""

import pandas as pwd

"""**2. IMPORTING THE DATASET INTO PROJECT**"""

data = pwd.read_csv('heart.csv')

# Checking for NULL Values within the dataset
data.isnull().sum()

# Removing Duplicated Values fron Dataset
duplicated = data.duplicated().any()
duplicated

data = data.drop_duplicates()

# Checking for Duplicated Values
duplicated = data.duplicated().any()
duplicated

"""```
Here we got no NULL Values present in the dataset because we've already removed them in previous code
```

**3. PROCESSING THE DATASET**
"""

valued = []
numeric = []

for column in data.columns:
  if data[column].nunique() <=10:
    valued.append(column)
  else:
    numeric.append(column)

# colums which contains string type values
valued

# columns which contains numeric type values
numeric

data.info()

data.describe()

data.shape

"""**4. FEATURE SCALING**"""

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()

data[numeric] = scaler.fit_transform(data[numeric])

data.head()

"""**5. SPLITTING THE DATA SET**"""

x = data.drop('target',axis=1)
y = data['target']

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)

x_test

y_test

"""**6. LOGISTIC REGRESSION**"""

from sklearn.linear_model import LogisticRegression
lr = LogisticRegression()
lr.fit(x_train,y_train)

y_pred = lr.predict(x_test)

from sklearn.metrics import accuracy_score
accuracy_score(y_test,y_pred)

"""**7. SUPPORT VECTOR CLASSIFIER**"""

from sklearn.svm import SVC
svc = SVC()
svc.fit(x_train,y_train)

y_pred2 = svc.predict(x_test)

accuracy_score(y_test,y_pred2)

"""**8. K-NEAREST NEIGHBOUR**"""

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier()
knn.fit(x_train,y_train)

y_pred3 = knn.predict(x_test)

accuracy_score(y_test,y_pred3)

"""```
score=[]
for k in range(1,30):
 knn = KNeighborsClassifier(n_neighbors=k)
  knn.fit(x_train,y_train)
  y_pred = knn.predict(x_test)
  score.append(accuracy_score(y_test,y_pred))
  ```
"""

knn = KNeighborsClassifier(n_neighbors=12)
knn.fit(x_train,y_train)
y_pred = knn.predict(x_test)
accuracy_score(y_test,y_pred)

"""**9. RANDOM FOREST CLASSIFIER**"""

from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier()
rf.fit(x_train,y_train)

y_pred4 = rf.predict(x_test)
accuracy_score(y_test,y_pred)

"""**10. GRADIENT BOOSTING CLASSIFIER**"""

from sklearn.ensemble import GradientBoostingClassifier
gbc = GradientBoostingClassifier()
gbc.fit(x_train,y_train)
y_pred5=gbc.predict(x_test)
accuracy_score(y_test,y_pred5)

"""**FINAL DATA**"""

final_data =  pwd.DataFrame({'Models':['Logistic Regression','Support Vector Classifier','K-Nearest Neighbour','Random Forest Classifier','Gradient Boosting Classifier'],'Accuracy':[accuracy_score(y_test,y_pred),
                                                                                                                                                                                     accuracy_score(y_test,y_pred2),
                                                                                                                                                                                     accuracy_score(y_test,y_pred3),
                                                                                                                                                                                     accuracy_score(y_test,y_pred4),
                                                                                                                                                                                     accuracy_score(y_test,y_pred5),]})
final_data

import matplotlib.pyplot as plt
plt.bar(final_data['Models'], final_data['Accuracy'], color=['blue', 'green', 'red', 'purple', 'orange'])
plt.xlabel('Models')
plt.ylabel('Accuracy')
plt.title('Accuracy of Different Models')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()